
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>SK Part 4: Cross-Validation and Hyper-parameter Tuning &#8212; Tutorials on Data Science with Python</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'ml/SK4_HyperParameter_Tuning';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="SK Part 5: Pipelines, Statistical Model Comparison, and Model Deployment" href="SK5_Advanced_Topics.html" />
    <link rel="prev" title="SK Part 3: Model Evaluation" href="SK3_Model_Evaluation.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
  
    <p class="title logo__title">Tutorials on Data Science with Python</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Welcome to D. Akman’s Tutorials on Data Science with Python!
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../python/README.html">Python Basics (PB) Tutorial Series</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../python/PB1_nb_intro.html">Introduction to Jupyter Notebooks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python/PB2_nb_markdown.html">Notebook Markdown Tutorial</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python/PB3_intro_to_python.html">Introduction to Python Programming</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python/PB4_numpy.html">NumPy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python/PB5_pandas.html">Pandas</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python/PB6_matplotlib.html">Matplotlib</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python/PB7_seaborn.html">Seaborn</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python/PB8_python_vs_r.html">Python vs. R</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../stats/README.html">Statistics Tutorials/ OpenIntro Labs for Python</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../stats/ch1n2_intro_to_data.html">Introduction to data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../stats/ch3_probability.html">Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../stats/ch4_normal_distribution.html">Normal distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../stats/ch5_confidence_intervals.html">Foundations for statistical inference - Confidence intervals</a></li>
<li class="toctree-l2"><a class="reference internal" href="../stats/ch5_sampling_distributions.html">Foundations for statistical inference - Sampling distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../stats/ch6_inf_for_categorical_data.html">Inference for categorical data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../stats/ch7_inf_for_numerical_data.html">Inference for numerical data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../stats/ch8_simple_regression.html">Introduction to linear regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../stats/ch9_multiple_regression.html">Multiple linear regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../stats/regression_case_study_predicting_age_in_census_data.html">Predicting Age in Census Data<a class="anchor-link" href="#Predicting-Age-in-Census-Data"></a></a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="README.html">Machine Learning Tutorials with Scikit-Learn</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="Data_Prep_for_Predictive_Modelling.html">Data Preparation for Predictive Modeling</a></li>
<li class="toctree-l2"><a class="reference internal" href="SK0_Scikit_Learn_Introduction.html">SK Part 0: Introduction to Predictive Modeling with Python and Scikit-Learn</a></li>
<li class="toctree-l2"><a class="reference internal" href="SK1_Basic_Modelling.html">SK Part 1: Basic Modeling</a></li>
<li class="toctree-l2"><a class="reference internal" href="SK2_Feature_Selection.html">SK Part 2: Feature Selection and Ranking</a></li>
<li class="toctree-l2"><a class="reference internal" href="SK3_Model_Evaluation.html">SK Part 3: Model Evaluation</a></li>

<li class="toctree-l2 current active"><a class="current reference internal" href="#">SK Part 4: Cross-Validation and Hyper-parameter Tuning</a></li>
<li class="toctree-l2"><a class="reference internal" href="SK5_Advanced_Topics.html">SK Part 5: Pipelines, Statistical Model Comparison, and Model Deployment</a></li>
<li class="toctree-l2"><a class="reference internal" href="SK6_Clustering.html">SK Part 6: K-Means Clustering</a></li>
<li class="toctree-l2"><a class="reference internal" href="SK7_Neural_Networks.html">SK Part 7: Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="SK8_LightGBM.html">Light GBM &amp; Parameter Tuning with Optuna</a></li>
<li class="toctree-l2"><a class="reference internal" href="SK9_Forecasting.html">Forecasting Fundamentals with Python &amp; Facebook Prophet</a></li>
<li class="toctree-l2"><a class="reference internal" href="Case_Study1_Predicting_Income_Status.html">Predicting Income Status</a></li>







<li class="toctree-l2"><a class="reference internal" href="Case_Study2_Maintenance_Predictive_Modelling.html">Predicting Optimal Machine Maintenance Cycle</a></li>
<li class="toctree-l2"><a class="reference internal" href="Case_Study3_Hotel_Prediction.html">Hotel Prediction with Hybrid Collaborative Filtering with SVD</a></li>

<li class="toctree-l2"><a class="reference internal" href="Decision_Trees_InfoGain_Computation.html">Information Gain Computation in Python</a></li>
</ul>
</details></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/ml/SK4_HyperParameter_Tuning.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>SK Part 4: Cross-Validation and Hyper-parameter Tuning</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-objectives">Learning Objectives</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#table-of-contents">Table of Contents</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#binary-classification-breast-cancer-wisconsin-data">Binary Classification: Breast Cancer Wisconsin Data <a class="anchor" id="1"></a></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-preparation">Data Preparation <a class="anchor" id="1.0"></a></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#nearest-neighbor-models">Nearest Neighbor Models <a class="anchor" id="1.1"></a></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cross-validation">Cross-Validation <a class="anchor" id="1.2"></a></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#knn-hyperparameter-tuning-and-visualization">KNN Hyperparameter Tuning and Visualization <a class="anchor" id="1.3"></a></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dt-hyperparameter-tuning-and-visualization">DT Hyperparameter Tuning and Visualization <a class="anchor" id="1.4"></a></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#nb-hyperparameter-tuning-and-visualization">NB Hyperparameter Tuning and Visualization <a class="anchor" id="1.5"></a></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#regression-example-california-housing-data">Regression Example: California Housing Data <a class="anchor" id="2"></a></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercises">Exercises <a class="anchor" id="3"></a></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#problem">Problem <a class="anchor" id="3.1"></a></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#possible-solution">Possible Solution <a class="anchor" id="3.2"></a></a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="sk-part-4-cross-validation-and-hyper-parameter-tuning">
<h1>SK Part 4: Cross-Validation and Hyper-parameter Tuning<a class="headerlink" href="#sk-part-4-cross-validation-and-hyper-parameter-tuning" title="Link to this heading">#</a></h1>
<p>In <strong>SK Part 1</strong>, we learn how to evaluate a machine learning model using the <code class="docutils literal notranslate"><span class="pre">train_test_split</span></code> function to split the full set into disjoint training and test sets based on a specified test size ratio. We then train the model (that is, “fit”) using the training set and evaluate it against the test set. This approach is called “hold-out sampling”. A more robust and methodical approach to hold-out sampling is “cross-validation”, which is the subject of this tutorial.</p>
<p>A critical step in machine learning is to find out the “optimal” parameters of a learner (such as the number of neighbors in a KNN model). In this tutorial, we illustrate how optimal model parameters can be identified using repeated cross-validation in a grid search framework.</p>
<section id="learning-objectives">
<h2>Learning Objectives<a class="headerlink" href="#learning-objectives" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Implement various cross-validation strategies.</p></li>
<li><p>Perform grid search to identify optimal hyperparameter values.</p></li>
</ul>
<p>As in Part 1, we shall use the following datasets for regression, binary, and multiclass classification problems.</p>
<ol class="arabic simple">
<li><p><a class="reference external" href="https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29">Breast Cancer Wisconsin Data</a>. The target feature is binary, i.e., if a cancer diagnosis is “malignant” or “benign”.</p></li>
<li><p><a class="reference external" href="https://www.kaggle.com/datasets/camnugent/california-housing-prices">California Housing Data</a>. The target feature is continuous, which is the house prices in California.</p></li>
<li><p><a class="reference external" href="https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data">Wine Data</a>. The target feature is multiclass. It consists of three types of wines in Italy.</p></li>
</ol>
<p>We use KNN, DT, and NB models to illustrate how cross-validation is used to tune hyperparameters of a machine learning algorithm via grid search by going through the Breast Cancer Data and California Housing Data. We will leave Wine Data and other machine learning models as exercises.</p>
</section>
<section id="table-of-contents">
<h2>Table of Contents<a class="headerlink" href="#table-of-contents" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p><a class="reference internal" href="#1"><span class="xref myst">Binary Classification Example: Breast Cancer Wisconsin Data</span></a></p>
<ul>
<li><p><a class="reference internal" href="#1.0"><span class="xref myst">Data Preparation</span></a></p></li>
<li><p><a class="reference internal" href="#1.1"><span class="xref myst">Nearest Neigbor Models</span></a></p></li>
<li><p><a class="reference internal" href="#1.2"><span class="xref myst">Cross-Validation</span></a></p></li>
<li><p><a class="reference internal" href="#1.3"><span class="xref myst">KNN Hyperparameter Tuning and Visualization</span></a></p></li>
<li><p><a class="reference internal" href="#1.4"><span class="xref myst">DT Hyperparameter Tuning and Visualization</span></a></p></li>
<li><p><a class="reference internal" href="#1.5"><span class="xref myst">NB Hyperparameter Tuning and Visualization</span></a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#2"><span class="xref myst">Regression Example: California Housing Data</span></a></p></li>
<li><p><a class="reference internal" href="#3"><span class="xref myst">Exercises</span></a></p>
<ul>
<li><p><a class="reference internal" href="#3.1"><span class="xref myst">Problems</span></a></p></li>
<li><p><a class="reference internal" href="#3.2"><span class="xref myst">Solutions</span></a></p></li>
</ul>
</li>
</ul>
</section>
<section id="binary-classification-breast-cancer-wisconsin-data">
<h2>Binary Classification: Breast Cancer Wisconsin Data <a class="anchor" id="1"></a><a class="headerlink" href="#binary-classification-breast-cancer-wisconsin-data" title="Link to this heading">#</a></h2>
<section id="data-preparation">
<h3>Data Preparation <a class="anchor" id="1.0"></a><a class="headerlink" href="#data-preparation" title="Link to this heading">#</a></h3>
<p>Let’s prepare the dataset for modeling by performing the following:</p>
<ul class="simple">
<li><p>load the dataset from <code class="docutils literal notranslate"><span class="pre">sklearn</span></code> (unlike the Cloud version, this version does not have column names),</p></li>
<li><p>normalize the descriptive features so that they have 0 mean and 1 standard deviation, and</p></li>
<li><p>split the dataset into training and test sets.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_breast_cancer</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">preprocessing</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">load_breast_cancer</span><span class="p">()</span>
<span class="n">Data</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">target</span>

<span class="n">Data</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">MinMaxScaler</span><span class="p">()</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">Data</span><span class="p">)</span>

<span class="c1"># target is already encoded, but we need to reverse the labels</span>
<span class="c1"># so that malignant is the positive class</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">target</span><span class="o">==</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

<span class="n">D_train</span><span class="p">,</span> <span class="n">D_test</span><span class="p">,</span> <span class="n">t_train</span><span class="p">,</span> <span class="n">t_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">Data</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">999</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="nearest-neighbor-models">
<h3>Nearest Neighbor Models <a class="anchor" id="1.1"></a><a class="headerlink" href="#nearest-neighbor-models" title="Link to this heading">#</a></h3>
<p>Let’s fit a 1-nearest neighbor (1-NN) classifier (<code class="docutils literal notranslate"><span class="pre">n_neighbors=1</span></code>) using the Euclidean distance (<code class="docutils literal notranslate"><span class="pre">p=2</span></code>).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>

<span class="n">knn_classifier</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">knn_classifier</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">D_train</span><span class="p">,</span> <span class="n">t_train</span><span class="p">)</span>
<span class="n">knn_classifier</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">D_test</span><span class="p">,</span> <span class="n">t_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.9473684210526315
</pre></div>
</div>
</div>
</div>
<p>The 1-NN classifier yields an accuracy score of around 94.7%. So, how can we improve this score? One way is to search the set of “hyperparameters” which produces the highest accuracy score. For a nearest neighbor model, the hyperparameters are as follows:</p>
<ul class="simple">
<li><p>Number of neighbors.</p></li>
<li><p>Metric: Manhattan (p=1), Euclidean (p=2) or Minkowski (any p larger than 2). Technically, p=1 and p=2 are also Minkowski metrics, but in this notebook, we shall adopt the convention that the Minkowski metric corresponds to <span class="math notranslate nohighlight">\(p \geq 3\)</span>.</p></li>
</ul>
<p>To search for the “best” set of hyperparameters, popular approaches are as follows:</p>
<ul class="simple">
<li><p>Random search: As its name suggests, it randomly selects the hyperparameter set to train models.</p></li>
<li><p>Bayesian search: It is beyond the scope of this course. So we shall not cover it here.</p></li>
<li><p>Grid search.</p></li>
</ul>
<p>Grid search is the most common approach. It exhaustively searches through all possible combinations of hyperparameters during training the phase. For example, consider a KNN model. We can specify a grid of number of neighbors (K = 1, 2, 3) and two metrics (p=1, 2). The grid search starts training a model of K = 1 and p=1 and calculates its accuracy score. Then it moves to train models of (K = 2, p = 1), (K = 3, p = 1), (K = 1, p = 2), …, and (K = 3, p = 2) and obtain their score values. Based on the accuracy scores, the grid search will rank the models and determine the set of hyperparameter values that give the highest accuracy score.</p>
<p>Before we proceed further, we shall cover other cross-validation (CV) methods since tuning hyperparameters via grid search is usually cross-validated to avoid overfitting.</p>
</section>
<section id="cross-validation">
<h3>Cross-Validation <a class="anchor" id="1.2"></a><a class="headerlink" href="#cross-validation" title="Link to this heading">#</a></h3>
<p>Two popular options for cross-validation are 5-fold and 10-fold. In 5-fold cross-validation, for instance, the entire dataset is partitioned into 5 equal-sized chunks. The first four chunks are used for training and the 5-th chunk is used for testing. Next, all the chunks other than the 4-th chunk are used for training and the 4-th chunk is used for testing, and so on. In the last iteration, all the chunks other than the 1-st chunk are used for training and the 1-st chunk is used for testing. The final step is to take the average of these 5 test accuracies and report it as the overall cross-validation accuracy. Please see the figure below for an illustration of a 10-fold cross-validation (source: <a class="reference external" href="http://karlrosaen.com/ml/learning-log/2016-06-20/">karlrosaen.com</a>) . Please refer to Chapter 8 in the textbook for more information.</p>
<p><img alt="k-fold-diagram.png" src="ml/attachment:k-fold-diagram.png" /></p>
<p>In contrast to hold-out-sampling, cross-validation is usually the preferred option due to the following two reasons:</p>
<ul class="simple">
<li><p>Sometimes there is just not enough data for a hold-out-sampling.</p></li>
<li><p>Cross-validation reduces the risk of what is called “lucky split” where the difficult instances are put in the training partition and the easy instances are put in the test partition.</p></li>
</ul>
<p>A downside of cross-validation is that it apparently requires more computer time. Also, if it happens to be the case that there is a good amount of data available already (say millions of rows), then the risk of “lucky split” diminishes and hold-out-sampling can be preferred. Another extension of cross-validation is repeated cross-validation (say 3 times) where data is partitioned into 5 equal-sized chunks multiple times and the cross-validation procedure is repeated, each time with a different partitioning of data per repeatition.</p>
<p>We can perform K-fold cross-validation by calling the <code class="docutils literal notranslate"><span class="pre">KFold</span></code> function imported from <code class="docutils literal notranslate"><span class="pre">sklearn.model_selection</span></code> module. It randomly splits the full dataset into K subsets or “folds”. Then it trains the model on K-1 folds and evaluates the model against the remaining fold. This process is repeated exactly K times where each time a different fold is used for testing.</p>
<p>Other cross-validation variants from <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> are as follows:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">model_selection.RepeatedKFold()</span></code>: Repeated K-Fold cross-validator</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">model_selection.RepeatedStratifiedKFold()</span></code>: Repeated Stratified K-Fold cross-validator</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">model_selection.StratifiedKFold()</span></code>: Stratified K-Fold cross-validator</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">model_selection.LeaveOneOut()</span></code>: Leave One Out cross-validator</p></li>
</ul>
<p>To learn more about cross-validators, please refer to <a class="reference external" href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection">scikit-learn documentation</a>.</p>
<p><strong>Refresher questions</strong></p>
<ol class="arabic simple">
<li><p>What are the disadvantages of a simple test/ train split?</p></li>
<li><p>Can you tell the difference between the cross-validators above?</p></li>
</ol>
<p>In the following example, we illustrate how we can conduct a stratified 5-fold (<code class="docutils literal notranslate"><span class="pre">n_splits</span> <span class="pre">=</span> <span class="pre">5</span></code>) cross-validation with 3 repetitions (<code class="docutils literal notranslate"><span class="pre">n_repeats</span> <span class="pre">=</span> <span class="pre">3</span></code>) using the <code class="docutils literal notranslate"><span class="pre">RepeatedStratifiedKFold</span></code> function. Since the target labels have fewer <code class="docutils literal notranslate"><span class="pre">malignant</span></code> labels than <code class="docutils literal notranslate"><span class="pre">benign</span></code>, stratification ensures that the proportion of the two labels in both train and test sets are the same as the proportion in the full dataset in each cross-validation repetition.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">RepeatedStratifiedKFold</span>

<span class="n">cv_method</span> <span class="o">=</span> <span class="n">RepeatedStratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> 
                                    <span class="n">n_repeats</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
                                    <span class="n">random_state</span><span class="o">=</span><span class="mi">999</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="knn-hyperparameter-tuning-and-visualization">
<h3>KNN Hyperparameter Tuning and Visualization <a class="anchor" id="1.3"></a><a class="headerlink" href="#knn-hyperparameter-tuning-and-visualization" title="Link to this heading">#</a></h3>
<p>It’s hyperparameter tuning time. First, we need to define a dictionary of KNN parameters for the grid search. Here, we will consider K values between 3 and 7 and <span class="math notranslate nohighlight">\(p\)</span> values of 1 (Manhattan), 2 (Euclidean), and 5 (Minkowski).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">params_KNN</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;n_neighbors&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span> 
              <span class="s1">&#39;p&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">]}</span>
</pre></div>
</div>
</div>
</div>
<p>Second, we pass the <code class="docutils literal notranslate"><span class="pre">KNeighborsClassifier()</span></code> and <code class="docutils literal notranslate"><span class="pre">KNN_params</span></code> as the model and the parameter dictionary into the <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> function. In addition, we include the repeated stratified CV method we defined previously (<code class="docutils literal notranslate"><span class="pre">cv=cv_method</span></code>). Also, we tell <code class="docutils literal notranslate"><span class="pre">sklearn</span></code> which metric to optimize, which is accuracy in our example (<code class="docutils literal notranslate"><span class="pre">scoring='accuracy'</span></code>, <code class="docutils literal notranslate"><span class="pre">refit='accuracy'</span></code>).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>

<span class="n">gs_KNN</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">KNeighborsClassifier</span><span class="p">(),</span> 
                      <span class="n">param_grid</span><span class="o">=</span><span class="n">params_KNN</span><span class="p">,</span> 
                      <span class="n">cv</span><span class="o">=</span><span class="n">cv_method</span><span class="p">,</span>
                      <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>  <span class="c1"># verbose: the higher, the more messages</span>
                      <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;accuracy&#39;</span><span class="p">,</span> 
                      <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The last step is to fit a KNN model using the full dataset.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gs_KNN</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Data</span><span class="p">,</span> <span class="n">target</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Fitting 15 folds for each of 21 candidates, totalling 315 fits
</pre></div>
</div>
</div>
</div>
<p>To get the best parameter values, we call the <code class="docutils literal notranslate"><span class="pre">best_params_</span></code> attribute.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gs_KNN</span><span class="o">.</span><span class="n">best_params_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;n_neighbors&#39;: 3, &#39;p&#39;: 1}
</pre></div>
</div>
</div>
</div>
<p>After stratified 5-fold cross-validation with 3 repeatitions, we observe that the optimal parameters are 6 neighbors using the Manhattan (p=1) distance metric. The mean cross-validation accuracy with the optimal parameters can be extracted using the <code class="docutils literal notranslate"><span class="pre">best_score</span></code> attribute.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gs_KNN</span><span class="o">.</span><span class="n">best_score_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>np.float64(0.9748227500905656)
</pre></div>
</div>
</div>
</div>
<p>To extract more cross-validation results, we can call <code class="docutils literal notranslate"><span class="pre">gs.csv_results</span></code> - a dictionary consisting of run details for each fold.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gs_KNN</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;mean_test_score&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([0.95136884, 0.95254878, 0.95021477, 0.9625317 , 0.95961807,
       0.95433939, 0.97482275, 0.97071883, 0.96135176, 0.96956477,
       0.97012886, 0.96429643, 0.97248357, 0.9689541 , 0.9619469 ,
       0.96721006, 0.96837448, 0.96428608, 0.97307354, 0.97012886,
       0.9619469 ])
</pre></div>
</div>
</div>
</div>
<p>Let’s visualize the hyperparameter tuning results from the cross-validation. We define a data frame by combining <code class="docutils literal notranslate"><span class="pre">gs.cv_results_['params']</span></code> and <code class="docutils literal notranslate"><span class="pre">gs.cv_results_['mean_test_score']</span></code>. The <code class="docutils literal notranslate"><span class="pre">gs.cv_results_['params']</span></code> is an array of hyperparameter combinations.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">results_KNN</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">gs_KNN</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;params&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results_KNN</span><span class="p">[</span><span class="s1">&#39;test_score&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">gs_KNN</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;mean_test_score&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s create a new column called “metric” that stores the name of the metric for each <span class="math notranslate nohighlight">\(p\)</span> value.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results_KNN</span><span class="p">[</span><span class="s1">&#39;metric&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">results_KNN</span><span class="p">[</span><span class="s1">&#39;p&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;Manhattan&quot;</span><span class="p">,</span> <span class="s2">&quot;Euclidean&quot;</span><span class="p">,</span> <span class="s2">&quot;Minkowski&quot;</span><span class="p">])</span>
<span class="n">results_KNN</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>n_neighbors</th>
      <th>p</th>
      <th>test_score</th>
      <th>metric</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>1</td>
      <td>0.951369</td>
      <td>Manhattan</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>2</td>
      <td>0.952549</td>
      <td>Euclidean</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>5</td>
      <td>0.950215</td>
      <td>Minkowski</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2</td>
      <td>1</td>
      <td>0.962532</td>
      <td>Manhattan</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2</td>
      <td>2</td>
      <td>0.959618</td>
      <td>Euclidean</td>
    </tr>
    <tr>
      <th>5</th>
      <td>2</td>
      <td>5</td>
      <td>0.954339</td>
      <td>Minkowski</td>
    </tr>
    <tr>
      <th>6</th>
      <td>3</td>
      <td>1</td>
      <td>0.974823</td>
      <td>Manhattan</td>
    </tr>
    <tr>
      <th>7</th>
      <td>3</td>
      <td>2</td>
      <td>0.970719</td>
      <td>Euclidean</td>
    </tr>
    <tr>
      <th>8</th>
      <td>3</td>
      <td>5</td>
      <td>0.961352</td>
      <td>Minkowski</td>
    </tr>
    <tr>
      <th>9</th>
      <td>4</td>
      <td>1</td>
      <td>0.969565</td>
      <td>Manhattan</td>
    </tr>
    <tr>
      <th>10</th>
      <td>4</td>
      <td>2</td>
      <td>0.970129</td>
      <td>Euclidean</td>
    </tr>
    <tr>
      <th>11</th>
      <td>4</td>
      <td>5</td>
      <td>0.964296</td>
      <td>Minkowski</td>
    </tr>
    <tr>
      <th>12</th>
      <td>5</td>
      <td>1</td>
      <td>0.972484</td>
      <td>Manhattan</td>
    </tr>
    <tr>
      <th>13</th>
      <td>5</td>
      <td>2</td>
      <td>0.968954</td>
      <td>Euclidean</td>
    </tr>
    <tr>
      <th>14</th>
      <td>5</td>
      <td>5</td>
      <td>0.961947</td>
      <td>Minkowski</td>
    </tr>
    <tr>
      <th>15</th>
      <td>6</td>
      <td>1</td>
      <td>0.967210</td>
      <td>Manhattan</td>
    </tr>
    <tr>
      <th>16</th>
      <td>6</td>
      <td>2</td>
      <td>0.968374</td>
      <td>Euclidean</td>
    </tr>
    <tr>
      <th>17</th>
      <td>6</td>
      <td>5</td>
      <td>0.964286</td>
      <td>Minkowski</td>
    </tr>
    <tr>
      <th>18</th>
      <td>7</td>
      <td>1</td>
      <td>0.973074</td>
      <td>Manhattan</td>
    </tr>
    <tr>
      <th>19</th>
      <td>7</td>
      <td>2</td>
      <td>0.970129</td>
      <td>Euclidean</td>
    </tr>
    <tr>
      <th>20</th>
      <td>7</td>
      <td>5</td>
      <td>0.961947</td>
      <td>Minkowski</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>We visualize the results using the <code class="docutils literal notranslate"><span class="pre">matplotlib</span></code> module. The plot below shows that K = 3 with the Manhattan distance metric (p=1) outperforms other combinations.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="k">matplotlib</span> inline 
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = &#39;retina&#39;
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">&quot;ggplot&quot;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;Manhattan&quot;</span><span class="p">,</span> <span class="s2">&quot;Euclidean&quot;</span><span class="p">,</span> <span class="s2">&quot;Minkowski&quot;</span><span class="p">]:</span>
    <span class="n">temp</span> <span class="o">=</span> <span class="n">results_KNN</span><span class="p">[</span><span class="n">results_KNN</span><span class="p">[</span><span class="s1">&#39;metric&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">i</span><span class="p">]</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">temp</span><span class="p">[</span><span class="s1">&#39;n_neighbors&#39;</span><span class="p">],</span> <span class="n">temp</span><span class="p">[</span><span class="s1">&#39;test_score&#39;</span><span class="p">],</span> <span class="n">marker</span> <span class="o">=</span> <span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="n">i</span><span class="p">)</span>
    
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Number of Neighbors&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Mean CV Score&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;KNN Performance Comparison&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="../_images/f4bd639617eeceb937af1668d58bc9c9bc6f4b29af097cd240fa5dcf11e5fe48.png"><img alt="../_images/f4bd639617eeceb937af1668d58bc9c9bc6f4b29af097cd240fa5dcf11e5fe48.png" src="../_images/f4bd639617eeceb937af1668d58bc9c9bc6f4b29af097cd240fa5dcf11e5fe48.png" style="width: 587px; height: 459px;" /></a>
</div>
</div>
</section>
<section id="dt-hyperparameter-tuning-and-visualization">
<h3>DT Hyperparameter Tuning and Visualization <a class="anchor" id="1.4"></a><a class="headerlink" href="#dt-hyperparameter-tuning-and-visualization" title="Link to this heading">#</a></h3>
<p>Let’s fit a decision tree model and optimize its hyperparameters using a grid search. We shall perform a grid search over split criterion, maximum depth, and minimum samples split parameters.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>

<span class="n">df_classifier</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">999</span><span class="p">)</span>

<span class="n">params_DT</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;criterion&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;gini&#39;</span><span class="p">,</span> <span class="s1">&#39;entropy&#39;</span><span class="p">],</span>
             <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span>
             <span class="s1">&#39;min_samples_split&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]}</span>

<span class="n">gs_DT</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">df_classifier</span><span class="p">,</span> 
                     <span class="n">param_grid</span><span class="o">=</span><span class="n">params_DT</span><span class="p">,</span> 
                     <span class="n">cv</span><span class="o">=</span><span class="n">cv_method</span><span class="p">,</span>
                     <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
                     <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;accuracy&#39;</span><span class="p">)</span>

<span class="n">gs_DT</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Data</span><span class="p">,</span> <span class="n">target</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Fitting 15 folds for each of 32 candidates, totalling 480 fits
</pre></div>
</div>
</div>
</div>
<p>Let’s have a look at the best performing parameter combination.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gs_DT</span><span class="o">.</span><span class="n">best_params_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;criterion&#39;: &#39;gini&#39;, &#39;max_depth&#39;: 5, &#39;min_samples_split&#39;: 2}
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gs_DT</span><span class="o">.</span><span class="n">best_score_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>np.float64(0.9338508513170833)
</pre></div>
</div>
</div>
</div>
<p>Let’s define a new data frame to store the DT grid search results for visualization.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results_DT</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">gs_DT</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;params&#39;</span><span class="p">])</span>
<span class="n">results_DT</span><span class="p">[</span><span class="s1">&#39;test_score&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">gs_DT</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;mean_test_score&#39;</span><span class="p">]</span>
<span class="n">results_DT</span><span class="o">.</span><span class="n">columns</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Index([&#39;criterion&#39;, &#39;max_depth&#39;, &#39;min_samples_split&#39;, &#39;test_score&#39;], dtype=&#39;object&#39;)
</pre></div>
</div>
</div>
</div>
<p>Now let’s do the plotting with respect to split criterion and maximum depth while taking the average of <code class="docutils literal notranslate"><span class="pre">min_samples_split</span></code> parameter.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;gini&#39;</span><span class="p">,</span> <span class="s1">&#39;entropy&#39;</span><span class="p">]:</span>
    <span class="n">temp</span> <span class="o">=</span> <span class="n">results_DT</span><span class="p">[</span><span class="n">results_DT</span><span class="p">[</span><span class="s1">&#39;criterion&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">i</span><span class="p">]</span>
    <span class="n">temp_average</span> <span class="o">=</span> <span class="n">temp</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;max_depth&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">agg</span><span class="p">({</span><span class="s1">&#39;test_score&#39;</span><span class="p">:</span> <span class="s1">&#39;mean&#39;</span><span class="p">})</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">temp_average</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="n">i</span><span class="p">)</span>
    
    
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Max Depth&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Mean CV Score&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;DT Performance Comparison&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="../_images/4a237beaba5a7bfdf9b1d38e2f6f4b8975d2f2f00ab3b072cf758b7e4213485f.png"><img alt="../_images/4a237beaba5a7bfdf9b1d38e2f6f4b8975d2f2f00ab3b072cf758b7e4213485f.png" src="../_images/4a237beaba5a7bfdf9b1d38e2f6f4b8975d2f2f00ab3b072cf758b7e4213485f.png" style="width: 578px; height: 459px;" /></a>
</div>
</div>
<p>We observe that the best set of hyperparameters is as follows: entropy split criterion with a maximum depth of 4 and <code class="docutils literal notranslate"><span class="pre">min_samples_split</span></code> value of 2.</p>
</section>
<section id="nb-hyperparameter-tuning-and-visualization">
<h3>NB Hyperparameter Tuning and Visualization <a class="anchor" id="1.5"></a><a class="headerlink" href="#nb-hyperparameter-tuning-and-visualization" title="Link to this heading">#</a></h3>
<p>Let’s fit a Gaussian Naive Bayes model and optimize its only parameter, <code class="docutils literal notranslate"><span class="pre">var_smoothing</span></code>, using a grid search. Variance smoothing can be considered to be a variant of Laplace smoothing in the sense that the <code class="docutils literal notranslate"><span class="pre">var_smoothing</span></code> parameter specifies the portion of the largest variance of all features to be added to variances for calculation stability.</p>
<p>Recall that Gaussian NB assumes that each one of the descriptive features follows a Gaussian, that is, normal distribution. This is highly unlikely in practice, but we can perform what is called a “power transformation” on each feature to make it more or less normally distributed. The link <a class="reference external" href="https://www.statisticshowto.datasciencecentral.com/box-cox-transformation/">here</a> is a good place to start learning about power transformations via its more specific case of Box-Cox transformations.</p>
<p>We perform power transformation using the <code class="docutils literal notranslate"><span class="pre">PowerTransformer</span></code> method in <code class="docutils literal notranslate"><span class="pre">sklearn</span></code>, but you need to make sure that you have the latest version of <code class="docutils literal notranslate"><span class="pre">sklearn</span></code> because this is a relatively new method. By default, <code class="docutils literal notranslate"><span class="pre">PowerTransformer</span></code> results in features that have a 0 mean and 1 standard deviation.</p>
<p>Let’s first have a look at an example of a power transformation. We define an exponential random variable with a mean of 2 and sample 1000 numbers from this distribution. Numbers sampled from this distribution are always positive and this distribution is quite right skewed as you can see in the plot below.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">PowerTransformer</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">999</span><span class="p">)</span>

<span class="n">sample_size</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">x_exponential</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">exponential</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">sample_size</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">x_transformed</span> <span class="o">=</span> <span class="n">PowerTransformer</span><span class="p">()</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">x_exponential</span><span class="p">)</span>

<span class="n">df1</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">x_exponential</span><span class="p">)</span>
<span class="n">df1</span><span class="p">[</span><span class="s1">&#39;distribution&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;exponential&#39;</span>

<span class="n">df2</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">x_transformed</span><span class="p">)</span>
<span class="n">df2</span><span class="p">[</span><span class="s1">&#39;distribution&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;transformed&#39;</span>

<span class="c1"># combine the two data frames into one to be used for plotting</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df1</span><span class="p">,</span> <span class="n">df2</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="s1">&#39;x&#39;</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">10</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>            x distribution
342 -0.276524  transformed
321  3.216755  exponential
247  1.297923  transformed
514 -1.678249  transformed
343  0.204341  exponential
386  0.486638  exponential
304  0.883091  exponential
772  0.015391  exponential
889  0.184597  transformed
554  0.076667  exponential
</pre></div>
</div>
</div>
</div>
<p>Once we perform a power transformation, we observe that the transformed numbers are centered at 0 and their distribution look like bell-curved.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;exponential&#39;</span><span class="p">,</span> <span class="s1">&#39;transformed&#39;</span><span class="p">]:</span>
    <span class="n">temp</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;distribution&#39;</span><span class="p">]</span><span class="o">==</span><span class="n">i</span><span class="p">]</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">temp</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">],</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.9</span><span class="p">,</span> <span class="n">bins</span> <span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="n">i</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x (binned)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Number of Records&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Power Transformation Example&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="../_images/891e2695777e7a000e38ffabf8aecffe4c128979fabce0d62faaa831443423b7.png"><img alt="../_images/891e2695777e7a000e38ffabf8aecffe4c128979fabce0d62faaa831443423b7.png" src="../_images/891e2695777e7a000e38ffabf8aecffe4c128979fabce0d62faaa831443423b7.png" style="width: 574px; height: 459px;" /></a>
</div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">var_smoothing</span></code> parameter’s default value is <span class="math notranslate nohighlight">\(10^{-9}\)</span>. We will conduct the grid search in the “logspace”, that is, we will search over the powers of 10. We will start with <span class="math notranslate nohighlight">\(10^0\)</span> and end with <span class="math notranslate nohighlight">\(10^{-9}\)</span> and we will try 100 different values. For this search, we will use the <code class="docutils literal notranslate"><span class="pre">logspace</span></code> function in the <code class="docutils literal notranslate"><span class="pre">numpy</span></code> module.</p>
<p>Here is how the logspace looks with 10 different values.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="o">-</span><span class="mi">9</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([1.e+00, 1.e-01, 1.e-02, 1.e-03, 1.e-04, 1.e-05, 1.e-06, 1.e-07,
       1.e-08, 1.e-09])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">GaussianNB</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">999</span><span class="p">)</span>

<span class="n">nb_classifier</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>

<span class="n">params_NB</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;var_smoothing&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="o">-</span><span class="mi">9</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">100</span><span class="p">)}</span>

<span class="n">gs_NB</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">nb_classifier</span><span class="p">,</span> 
                     <span class="n">param_grid</span><span class="o">=</span><span class="n">params_NB</span><span class="p">,</span> 
                     <span class="n">cv</span><span class="o">=</span><span class="n">cv_method</span><span class="p">,</span>
                     <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
                     <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;accuracy&#39;</span><span class="p">)</span>

<span class="n">Data_transformed</span> <span class="o">=</span> <span class="n">PowerTransformer</span><span class="p">()</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">Data</span><span class="p">)</span>

<span class="n">gs_NB</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Data_transformed</span><span class="p">,</span> <span class="n">target</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Fitting 15 folds for each of 100 candidates, totalling 1500 fits
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gs_NB</span><span class="o">.</span><span class="n">best_params_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;var_smoothing&#39;: np.float64(0.1)}
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gs_NB</span><span class="o">.</span><span class="n">best_score_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>np.float64(0.947891114216219)
</pre></div>
</div>
</div>
</div>
<p>Let’s define a new data frame to store the NB grid search results for visualization.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results_NB</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">gs_NB</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;params&#39;</span><span class="p">])</span>
<span class="n">results_NB</span><span class="p">[</span><span class="s1">&#39;test_score&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">gs_NB</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;mean_test_score&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Now let’s do the plotting with respect to the <code class="docutils literal notranslate"><span class="pre">var_smoothing</span></code> parameter.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">results_NB</span><span class="p">[</span><span class="s1">&#39;var_smoothing&#39;</span><span class="p">],</span> <span class="n">results_NB</span><span class="p">[</span><span class="s1">&#39;test_score&#39;</span><span class="p">],</span> <span class="n">marker</span> <span class="o">=</span> <span class="s1">&#39;.&#39;</span><span class="p">)</span>    
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Var. Smoothing&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Mean CV Score&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;NB Performance Comparison&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="../_images/cdb0ad04038f22e048d4b6cccaa42a929ea6a6cd87c3dbde5414cd2c123a304a.png"><img alt="../_images/cdb0ad04038f22e048d4b6cccaa42a929ea6a6cd87c3dbde5414cd2c123a304a.png" src="../_images/cdb0ad04038f22e048d4b6cccaa42a929ea6a6cd87c3dbde5414cd2c123a304a.png" style="width: 587px; height: 459px;" /></a>
</div>
</div>
<p>We observe that the best variance smoothing parameter for NB is around 0.1, though the difference between other values in terms of the mean CV score is very small per the range of the y-axis.</p>
</section>
</section>
<section id="regression-example-california-housing-data">
<h2>Regression Example: California Housing Data <a class="anchor" id="2"></a><a class="headerlink" href="#regression-example-california-housing-data" title="Link to this heading">#</a></h2>
<p>Let’s consider the California housing dataset. We call <code class="docutils literal notranslate"><span class="pre">KNeighborsRegressor</span></code> to run KNN on this regression problem. The KNN regression grid search is similar to its classification counterpart except for the differences below.</p>
<ul class="simple">
<li><p>We can no longer use stratified K-fold validation since the target is not multiclass or binary. However, we can use other methods such as K-fold or Repeated K-fold.</p></li>
<li><p>The model performance metric is no longer “accuracy”, but MSE (Mean Squared Error). We do not need to specify “mse” in <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> since <code class="docutils literal notranslate"><span class="pre">sklearn</span></code> is smart enough to figure out that the target is a continuous variable.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">fetch_california_housing</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsRegressor</span>

<span class="n">housing_data</span> <span class="o">=</span> <span class="n">fetch_california_housing</span><span class="p">()</span>
<span class="n">Data</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">housing_data</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">housing_data</span><span class="o">.</span><span class="n">target</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">RepeatedKFold</span><span class="p">,</span> <span class="n">GridSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>

<span class="n">cv_method</span> <span class="o">=</span> <span class="n">RepeatedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> 
                          <span class="n">n_repeats</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
                          <span class="n">random_state</span><span class="o">=</span><span class="mi">999</span><span class="p">)</span>

<span class="n">Data</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">Data</span><span class="p">)</span>

<span class="n">knn_regressor</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">()</span>

<span class="n">params_knn_regressor</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;n_neighbors&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">],</span> 
                        <span class="s1">&#39;p&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">]}</span>

<span class="n">gs_knn_regressor</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">knn_regressor</span><span class="p">,</span> 
                  <span class="n">param_grid</span><span class="o">=</span><span class="n">params_knn_regressor</span><span class="p">,</span> 
                  <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
                  <span class="n">cv</span><span class="o">=</span><span class="n">cv_method</span><span class="p">)</span>

<span class="n">gs_knn_regressor</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Data</span><span class="p">,</span> <span class="n">target</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Fitting 15 folds for each of 15 candidates, totalling 225 fits
</pre></div>
</div>
</div>
</div>
<p>After 3 repeated 5-fold cross-validation, we observe that the best parameters and best score are as follows:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gs_knn_regressor</span><span class="o">.</span><span class="n">best_params_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;n_neighbors&#39;: 5, &#39;p&#39;: 1}
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gs_knn_regressor</span><span class="o">.</span><span class="n">best_score_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>np.float64(0.7219548006539308)
</pre></div>
</div>
</div>
</div>
</section>
<section id="exercises">
<h2>Exercises <a class="anchor" id="3"></a><a class="headerlink" href="#exercises" title="Link to this heading">#</a></h2>
<section id="problem">
<h3>Problem <a class="anchor" id="3.1"></a><a class="headerlink" href="#problem" title="Link to this heading">#</a></h3>
<p>Run a decision tree model on Wine Data and tune its hyperparameters using a stratified repeated CV.</p>
</section>
<section id="possible-solution">
<h3>Possible Solution <a class="anchor" id="3.2"></a><a class="headerlink" href="#possible-solution" title="Link to this heading">#</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_wine</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">RepeatedStratifiedKFold</span><span class="p">,</span> <span class="n">GridSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>

<span class="n">wine</span> <span class="o">=</span> <span class="n">load_wine</span><span class="p">()</span>
<span class="n">Data</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">wine</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">wine</span><span class="o">.</span><span class="n">target</span>

<span class="n">Data</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">Data</span><span class="p">)</span>

<span class="n">cv_method</span> <span class="o">=</span> <span class="n">RepeatedStratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> 
                                    <span class="n">n_repeats</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> 
                                    <span class="n">random_state</span> <span class="o">=</span> <span class="mi">999</span><span class="p">)</span>

<span class="n">dt_classifier</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">999</span><span class="p">)</span>

<span class="n">params_DT</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;criterion&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;gini&#39;</span><span class="p">,</span> <span class="s1">&#39;entropy&#39;</span><span class="p">],</span>
             <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]}</span>

<span class="n">gs</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">dt_classifier</span><span class="p">,</span> 
                  <span class="n">param_grid</span><span class="o">=</span><span class="n">params_DT</span><span class="p">,</span> 
                  <span class="n">cv</span><span class="o">=</span><span class="n">cv_method</span><span class="p">,</span>
                  <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
                  <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;accuracy&#39;</span><span class="p">)</span>                  

<span class="nb">print</span><span class="p">(</span><span class="n">gs</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Data</span><span class="p">,</span> <span class="n">target</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">gs</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">gs</span><span class="o">.</span><span class="n">best_score_</span><span class="p">)</span>

</pre></div>
</div>
<hr class="docutils" />
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./ml"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="SK3_Model_Evaluation.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">SK Part 3: Model Evaluation</p>
      </div>
    </a>
    <a class="right-next"
       href="SK5_Advanced_Topics.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">SK Part 5: Pipelines, Statistical Model Comparison, and Model Deployment</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-objectives">Learning Objectives</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#table-of-contents">Table of Contents</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#binary-classification-breast-cancer-wisconsin-data">Binary Classification: Breast Cancer Wisconsin Data <a class="anchor" id="1"></a></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-preparation">Data Preparation <a class="anchor" id="1.0"></a></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#nearest-neighbor-models">Nearest Neighbor Models <a class="anchor" id="1.1"></a></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cross-validation">Cross-Validation <a class="anchor" id="1.2"></a></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#knn-hyperparameter-tuning-and-visualization">KNN Hyperparameter Tuning and Visualization <a class="anchor" id="1.3"></a></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dt-hyperparameter-tuning-and-visualization">DT Hyperparameter Tuning and Visualization <a class="anchor" id="1.4"></a></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#nb-hyperparameter-tuning-and-visualization">NB Hyperparameter Tuning and Visualization <a class="anchor" id="1.5"></a></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#regression-example-california-housing-data">Regression Example: California Housing Data <a class="anchor" id="2"></a></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercises">Exercises <a class="anchor" id="3"></a></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#problem">Problem <a class="anchor" id="3.1"></a></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#possible-solution">Possible Solution <a class="anchor" id="3.2"></a></a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By D. Akman
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>